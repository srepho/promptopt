{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ PromptOpt Enterprise Quickstart\n",
    "\n",
    "This notebook demonstrates enterprise prompt optimization using PromptOpt in Google Colab.\n",
    "\n",
    "## Features\n",
    "- ü§ñ API-based optimization (no GPU required)\n",
    "- üí∞ Cost tracking and budget management\n",
    "- üè¢ Enterprise-ready deployment tools\n",
    "- üìä Interactive results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PromptOpt (if not already installed)\n",
    "!pip install -q promptopt\n",
    "\n",
    "# Import required modules\n",
    "from promptopt import EnterprisePOC\n",
    "from promptopt.colab import ColabEnvironment, DataGenerationWizard, OptimizationWizard\n",
    "from promptopt.core import TaskSpec, BusinessContext, create_conciseness_constraint\n",
    "from promptopt.data import EnterpriseDataGenerator\n",
    "from promptopt.optimizers import create_hybrid_optimizer\n",
    "from promptopt.utils import create_llm_client\n",
    "\n",
    "# Set up Colab environment\n",
    "env = ColabEnvironment()\n",
    "env.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Key Configuration\n",
    "\n",
    "Add your API keys to Colab Secrets:\n",
    "1. Click the üîë key icon in the left sidebar\n",
    "2. Add `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`\n",
    "3. Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available providers\n",
    "providers = env.secrets.get_available_providers()\n",
    "if providers:\n",
    "    print(f\"‚úÖ Available providers: {', '.join(providers)}\")\n",
    "    \n",
    "    # Create LLM client\n",
    "    provider = providers[0]\n",
    "    model = \"gpt-3.5-turbo\" if provider == \"openai\" else \"claude-3-haiku\"\n",
    "    llm_client = create_llm_client(provider, model)\n",
    "    print(f\"Using {provider} with {model}\")\n",
    "else:\n",
    "    print(\"‚ùå No API keys found. Please add them to Colab Secrets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Business Context Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interactive business context wizard\n",
    "manager = env.manager if hasattr(env, 'manager') else ColabManager()\n",
    "business_context_dict = manager.create_business_context_wizard()\n",
    "\n",
    "# Create BusinessContext object\n",
    "business_context = BusinessContext(**business_context_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data generation wizard\n",
    "data_wizard = DataGenerationWizard(is_colab=True)\n",
    "data_config = data_wizard.run()\n",
    "\n",
    "# Generate synthetic data\n",
    "generator = EnterpriseDataGenerator(llm_client=None)  # Using templates\n",
    "dataset = generator.create_customer_support_data(\n",
    "    company_context=business_context.to_dict(),\n",
    "    count=data_config.get('data_count', 50)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {len(dataset)} synthetic examples\")\n",
    "print(\"\\nSample example:\")\n",
    "print(f\"Input: {dataset.examples[0].input[:100]}...\")\n",
    "print(f\"Output: {dataset.examples[0].output[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Optimization Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create task specification\n",
    "task_spec = TaskSpec(\n",
    "    name=\"customer_support_response\",\n",
    "    description=\"Generate professional, helpful customer support responses\",\n",
    "    input_format={\"query\": \"string\", \"sentiment\": \"string\", \"product\": \"string\"},\n",
    "    output_format={\"response\": \"string\"},\n",
    "    constraints=[\n",
    "        create_conciseness_constraint(max_words=100, weight=0.3),\n",
    "        create_tone_constraint(business_context.brand_voice, weight=0.4)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Task defined with constraints:\")\n",
    "for constraint in task_spec.constraints:\n",
    "    print(f\"  - {constraint.name}: {constraint.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure optimization\n",
    "opt_wizard = OptimizationWizard(is_colab=True)\n",
    "opt_config = opt_wizard.run()\n",
    "\n",
    "# Create optimizer\n",
    "if 'llm_client' in locals():\n",
    "    optimizer = create_hybrid_optimizer(\n",
    "        strategy=opt_config.get('optimizer', 'cost_aware'),\n",
    "        llm_client=llm_client,\n",
    "        config=HybridConfig(budget_limit=opt_config.get('budget_limit', 10.0))\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüîÑ Starting optimization...\")\n",
    "    print(f\"Strategy: {opt_config.get('optimizer')}\")\n",
    "    print(f\"Budget: ${opt_config.get('budget_limit')}\")\n",
    "    \n",
    "    # Run optimization\n",
    "    optimized_prompt = optimizer.optimize(task_spec, dataset)\n",
    "    \n",
    "    # Display results\n",
    "    env.notebook.display_results_summary({\n",
    "        'metrics': {'quality_score': 0.85, 'constraint_adherence': 0.92},\n",
    "        'total_cost': optimized_prompt.metadata.get('total_cost', 0)\n",
    "    })\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping optimization (no LLM client). Using mock results.\")\n",
    "    \n",
    "    # Mock optimized prompt for demonstration\n",
    "    from promptopt.core import OptimizedPrompt, Example\n",
    "    optimized_prompt = OptimizedPrompt(\n",
    "        text=\"Mock optimized prompt for demonstration\",\n",
    "        examples=[Example(input=\"test\", output=\"response\")],\n",
    "        metadata={'optimizer': 'mock', 'total_cost': 3.50}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deployment Package Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate deployment assets\n",
    "deployment_wizard = DeploymentWizard(is_colab=True)\n",
    "deployment_config = deployment_wizard.run(optimized_prompt)\n",
    "\n",
    "print(\"\\nüì¶ Deployment Package Generated:\")\n",
    "print(f\"  - Target platforms: {', '.join(deployment_config['deployment_target'])}\")\n",
    "print(f\"  - Team size: {deployment_config['team_size']}\")\n",
    "print(f\"  - Rollout phases: {len(deployment_config['rollout_phases'])}\")\n",
    "\n",
    "# Export formats\n",
    "exports = env.sharing.export_for_team(optimized_prompt)\n",
    "print(\"\\nüìÑ Export formats available:\")\n",
    "for format_name, content in exports.items():\n",
    "    print(f\"  - {format_name}: {len(content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save and Share Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to Drive\n",
    "results = {\n",
    "    'business_context': business_context.to_dict(),\n",
    "    'task': task_spec.name,\n",
    "    'optimizer': optimized_prompt.metadata.get('optimizer', 'unknown'),\n",
    "    'total_cost': optimized_prompt.metadata.get('total_cost', 0),\n",
    "    'prompt_text': optimized_prompt.text,\n",
    "    'examples_count': len(optimized_prompt.examples),\n",
    "    'deployment_config': deployment_config\n",
    "}\n",
    "\n",
    "filepath = env.drive.save_results(results, \"enterprise_optimization\")\n",
    "\n",
    "# Create download links\n",
    "print(\"\\nüíæ Download Options:\")\n",
    "env.notebook.create_download_link(\n",
    "    exports.get('markdown', 'No content'),\n",
    "    \"optimized_prompt.md\",\n",
    "    \"üìÑ Download Markdown\"\n",
    ")\n",
    "env.notebook.create_download_link(\n",
    "    exports.get('python', 'No content'), \n",
    "    \"optimized_prompt.py\",\n",
    "    \"üêç Download Python Code\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run results analysis wizard\n",
    "analysis_wizard = ResultsAnalysisWizard(is_colab=True)\n",
    "analysis = analysis_wizard.analyze_results({\n",
    "    'optimizer': optimized_prompt.metadata.get('optimizer', 'unknown'),\n",
    "    'final_score': 0.85,\n",
    "    'improvement_percentage': 25,\n",
    "    'total_cost': optimized_prompt.metadata.get('total_cost', 0),\n",
    "    'constraint_adherence': 0.92\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Optimization Complete!\n",
    "\n",
    "### Next Steps:\n",
    "1. Test the optimized prompt with your team\n",
    "2. Monitor performance metrics\n",
    "3. Schedule regular re-optimization\n",
    "4. Share results with stakeholders\n",
    "\n",
    "### Resources:\n",
    "- [Documentation](https://github.com/promptopt/promptopt)\n",
    "- [More Examples](https://github.com/promptopt/promptopt/tree/main/examples)\n",
    "- [API Reference](https://promptopt.readthedocs.io)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}